{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID-Title_Khushboo.ipynb",
      "provenance": [],
      "mount_file_id": "1M0uuUoE7huMI8UZgFm5RSkwjyPRwHdCL",
      "authorship_tag": "ABX9TyNTiCXexPw/xCUVhNUFB1Hp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namyalg/Topic-Modeling/blob/master/COVID_Title_Khushboo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-kyl5khMYUi",
        "outputId": "567e4f29-daa5-4982-c176-ae3275ee961a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "stop = set(stopwords.words('english'))\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim import corpora, models\n",
        "import gensim\n",
        "import string\n",
        "exclude = set(string.punctuation)\n",
        "lemma = WordNetLemmatizer()\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUaw9ZUuMhiS"
      },
      "source": [
        "import csv\n",
        "from csv import reader\n",
        "tit = []\n",
        "with open(\"/content/drive/My Drive/topic modelling dataset/COVID-19_title.csv\", 'r') as read_obj:\n",
        "    # pass the file object to reader() to get the reader object\n",
        "    csv_reader = reader(read_obj)\n",
        "    # Iterate over each row in the csv using reader object\n",
        "    for row in csv_reader:\n",
        "        # row variable is a list that represents a row in csv\n",
        "        tit.append(row)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7F9ExiQMrqL"
      },
      "source": [
        "val = []\n",
        "for i in tit:\n",
        "  val.append(i[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaLPusM_OuZE"
      },
      "source": [
        "Using Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvz-dxB6OMYm",
        "outputId": "c86fc6c3-9993-4578-b78e-5c9708e3c53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "# create English stop words list\n",
        "en_stop = set(stopwords.words('english'))\n",
        "# Create p_stemmer of class PorterStemmer\n",
        "p_stemmer = PorterStemmer()\n",
        "    \n",
        "doc_set = val\n",
        "# list for tokenized documents in loop\n",
        "texts = []\n",
        "\n",
        "# loop through document list\n",
        "for i in doc_set:\n",
        "    \n",
        "    # clean and tokenize document string\n",
        "    raw = i.lower()\n",
        "    tokens = tokenizer.tokenize(raw)\n",
        "    texts.append(tokens)\n",
        "\n",
        "# turn our tokenized documents into a id <-> term dictionary\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "    \n",
        "# convert tokenized documents into a document-term matrix\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "corpus[:2]\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1),\n",
              "  (1, 1),\n",
              "  (2, 1),\n",
              "  (3, 1),\n",
              "  (4, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (7, 1),\n",
              "  (8, 1),\n",
              "  (9, 1),\n",
              "  (10, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (13, 1)],\n",
              " [(14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OswEtwF3PGAq",
        "outputId": "c6acd0d2-7432-4601-9292-8b918af4b51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "preview = corpus[-1]\n",
        "for i in range(len(preview)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(preview[i][0], \n",
        "                                               dictionary[preview[i][0]], preview[i][1]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 167 (\"genomic\") appears 1 time.\n",
            "Word 268 (\"2\") appears 1 time.\n",
            "Word 389 (\"approach\") appears 1 time.\n",
            "Word 551 (\"computational\") appears 1 time.\n",
            "Word 698 (\"biology\") appears 1 time.\n",
            "Word 1080 (\"variations\") appears 1 time.\n",
            "Word 1201 (\"cov\") appears 1 time.\n",
            "Word 1202 (\"sars\") appears 1 time.\n",
            "Word 1290 (\"glycoprotein\") appears 1 time.\n",
            "Word 2058 (\"proteomic\") appears 1 time.\n",
            "Word 2435 (\"spike\") appears 1 time.\n",
            "Word 4902 (\"exploring\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_mD-GjwOzcz"
      },
      "source": [
        "Using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P4yWDUpOx6Q",
        "outputId": "4e523ed5-2a2c-4cc5-cddb-6a33ec745d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from gensim import corpora, models\n",
        "tfidf = models.TfidfModel(corpus)\n",
        "corpus_tfidf = tfidf[corpus]\n",
        "\n",
        "from pprint import pprint\n",
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.4008391105373045),\n",
            " (1, 0.24567875372913753),\n",
            " (2, 0.12458921372558343),\n",
            " (3, 0.25496299665686567),\n",
            " (4, 0.2004734464233877),\n",
            " (5, 0.16736632379793243),\n",
            " (6, 0.16468704915717103),\n",
            " (7, 0.3668081059363934),\n",
            " (8, 0.3197397997903073),\n",
            " (9, 0.2707589909539692),\n",
            " (10, 0.2722632346863148),\n",
            " (11, 0.3321192241618655),\n",
            " (12, 0.23860630098681238),\n",
            " (13, 0.2272946768906055)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB-oH5eYP0Na"
      },
      "source": [
        "Running LDA using Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaO5W0TzPAP8"
      },
      "source": [
        "lda_model = gensim.models.LdaMulticore(corpus, num_topics=8, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEa-VfuAP7Xy",
        "outputId": "cfa20fb3-3e14-475a-dde2-984e2fdedb56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.172*\"covid\" + 0.168*\"19\" + 0.022*\"coronavirus\" + 0.019*\"pandem\" + 0.018*\"disease\" + 0.018*\"pandemic\" + 0.017*\"2019\" + 0.015*\"patients\" + 0.008*\"during\" + 0.007*\"clinical\"\n",
            "Topic: 1 \n",
            "Words: 0.050*\"sars\" + 0.046*\"cov\" + 0.043*\"2\" + 0.021*\"virus\" + 0.018*\"coronavirus\" + 0.015*\"human\" + 0.014*\"protein\" + 0.012*\"viral\" + 0.010*\"detection\" + 0.010*\"infection\"\n",
            "Topic: 2 \n",
            "Words: 0.010*\"angiotensin\" + 0.009*\"induced\" + 0.008*\"system\" + 0.008*\"lung\" + 0.006*\"role\" + 0.006*\"enzyme\" + 0.005*\"1\" + 0.005*\"receptor\" + 0.005*\"inhibitors\" + 0.004*\"cell\"\n",
            "Topic: 3 \n",
            "Words: 0.032*\"health\" + 0.011*\"pandemic\" + 0.011*\"care\" + 0.010*\"review\" + 0.009*\"public\" + 0.008*\"among\" + 0.008*\"outbreak\" + 0.007*\"social\" + 0.007*\"global\" + 0.007*\"healthcare\"\n",
            "Topic: 4 \n",
            "Words: 0.014*\"tract\" + 0.011*\"protective\" + 0.009*\"personal\" + 0.009*\"infections\" + 0.007*\"asthma\" + 0.007*\"policy\" + 0.006*\"telemedicine\" + 0.006*\"equipment\" + 0.005*\"chloroquine\" + 0.005*\"viral\"\n",
            "Topic: 5 \n",
            "Words: 0.037*\"virus\" + 0.019*\"infectious\" + 0.018*\"influenza\" + 0.013*\"porcine\" + 0.008*\"chapter\" + 0.008*\"emerging\" + 0.008*\"coronavirus\" + 0.007*\"diarrhea\" + 0.007*\"epidemic\" + 0.007*\"viruses\"\n",
            "Topic: 6 \n",
            "Words: 0.019*\"case\" + 0.017*\"infection\" + 0.014*\"sars\" + 0.009*\"transmission\" + 0.008*\"cov\" + 0.008*\"report\" + 0.007*\"model\" + 0.007*\"2\" + 0.006*\"manifestations\" + 0.005*\"covid19\"\n",
            "Topic: 7 \n",
            "Words: 0.042*\"respiratory\" + 0.031*\"acute\" + 0.029*\"patients\" + 0.025*\"syndrome\" + 0.024*\"severe\" + 0.014*\"clinical\" + 0.013*\"coronavirus\" + 0.012*\"pneumonia\" + 0.011*\"studi\" + 0.010*\"children\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCcPnQ8bRRvT"
      },
      "source": [
        "Running LDA using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td4-d808QosW",
        "outputId": "ced8a0a1-b752-4534-fa70-87386f24322e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=8, id2word=dictionary, passes=2, workers=4)\n",
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 Word: 0.010*\"covid\" + 0.009*\"19\" + 0.005*\"pandem\" + 0.004*\"pandemic\" + 0.003*\"hydroxychloroquine\" + 0.003*\"stroke\" + 0.003*\"chloroquine\" + 0.002*\"during\" + 0.002*\"reflections\" + 0.002*\"coronavirus\"\n",
            "\n",
            "\n",
            "Topic: 1 Word: 0.007*\"covid\" + 0.007*\"19\" + 0.004*\"anxiety\" + 0.003*\"fatality\" + 0.003*\"storm\" + 0.003*\"pandem\" + 0.002*\"pandemic\" + 0.002*\"radiology\" + 0.002*\"caring\" + 0.002*\"embolism\"\n",
            "\n",
            "\n",
            "Topic: 2 Word: 0.009*\"covid\" + 0.009*\"19\" + 0.004*\"social\" + 0.004*\"pandem\" + 0.004*\"letter\" + 0.004*\"distancing\" + 0.004*\"pandemic\" + 0.004*\"health\" + 0.004*\"editor\" + 0.003*\"coronavirus\"\n",
            "\n",
            "\n",
            "Topic: 3 Word: 0.009*\"19\" + 0.009*\"covid\" + 0.006*\"angiotensin\" + 0.004*\"patients\" + 0.004*\"disease\" + 0.004*\"wuhan\" + 0.004*\"coronavirus\" + 0.003*\"diabetes\" + 0.003*\"system\" + 0.003*\"china\"\n",
            "\n",
            "\n",
            "Topic: 4 Word: 0.012*\"virus\" + 0.010*\"sars\" + 0.009*\"cov\" + 0.008*\"2\" + 0.007*\"coronavirus\" + 0.007*\"protein\" + 0.006*\"human\" + 0.005*\"viral\" + 0.004*\"respiratory\" + 0.004*\"porcine\"\n",
            "\n",
            "\n",
            "Topic: 5 Word: 0.011*\"respiratory\" + 0.011*\"patients\" + 0.011*\"19\" + 0.011*\"covid\" + 0.010*\"coronavirus\" + 0.009*\"2019\" + 0.009*\"disease\" + 0.008*\"acute\" + 0.008*\"clinical\" + 0.007*\"severe\"\n",
            "\n",
            "\n",
            "Topic: 6 Word: 0.004*\"laparoscopic\" + 0.004*\"covid\" + 0.004*\"19\" + 0.004*\"plasma\" + 0.004*\"convalescent\" + 0.004*\"surgery\" + 0.003*\"single\" + 0.003*\"intubation\" + 0.002*\"cancer\" + 0.002*\"patients\"\n",
            "\n",
            "\n",
            "Topic: 7 Word: 0.014*\"covid\" + 0.014*\"19\" + 0.010*\"health\" + 0.009*\"pandemic\" + 0.008*\"pandem\" + 0.007*\"care\" + 0.006*\"outbreak\" + 0.005*\"impact\" + 0.005*\"disease\" + 0.005*\"coronavirus\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-LnYfiTSWim"
      },
      "source": [
        "Performance evaluation of LDA using Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfqqcQyfRaNH",
        "outputId": "f389bda0-f771-43ec-9009-a50758d3392e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "texts[13]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vaccinia',\n",
              " 'virus',\n",
              " 'infection',\n",
              " 'disrupts',\n",
              " 'microtubule',\n",
              " 'organization',\n",
              " 'centrosome',\n",
              " 'funct']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlBzzLcwTjtr",
        "outputId": "5190f5e3-0828-4702-e1d6-73e2dee20f72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "for index, score in sorted(lda_model[corpus[13]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 8)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.7270503044128418\t \n",
            "Topic: 0.050*\"sars\" + 0.046*\"cov\" + 0.043*\"2\" + 0.021*\"virus\" + 0.018*\"coronavirus\" + 0.015*\"human\" + 0.014*\"protein\" + 0.012*\"viral\"\n",
            "\n",
            "Score: 0.18955178558826447\t \n",
            "Topic: 0.019*\"case\" + 0.017*\"infection\" + 0.014*\"sars\" + 0.009*\"transmission\" + 0.008*\"cov\" + 0.008*\"report\" + 0.007*\"model\" + 0.007*\"2\"\n",
            "\n",
            "Score: 0.013915383256971836\t \n",
            "Topic: 0.032*\"health\" + 0.011*\"pandemic\" + 0.011*\"care\" + 0.010*\"review\" + 0.009*\"public\" + 0.008*\"among\" + 0.008*\"outbreak\" + 0.007*\"social\"\n",
            "\n",
            "Score: 0.01390310749411583\t \n",
            "Topic: 0.010*\"angiotensin\" + 0.009*\"induced\" + 0.008*\"system\" + 0.008*\"lung\" + 0.006*\"role\" + 0.006*\"enzyme\" + 0.005*\"1\" + 0.005*\"receptor\"\n",
            "\n",
            "Score: 0.013900857418775558\t \n",
            "Topic: 0.037*\"virus\" + 0.019*\"infectious\" + 0.018*\"influenza\" + 0.013*\"porcine\" + 0.008*\"chapter\" + 0.008*\"emerging\" + 0.008*\"coronavirus\" + 0.007*\"diarrhea\"\n",
            "\n",
            "Score: 0.013894373551011086\t \n",
            "Topic: 0.014*\"tract\" + 0.011*\"protective\" + 0.009*\"personal\" + 0.009*\"infections\" + 0.007*\"asthma\" + 0.007*\"policy\" + 0.006*\"telemedicine\" + 0.006*\"equipment\"\n",
            "\n",
            "Score: 0.013893337920308113\t \n",
            "Topic: 0.042*\"respiratory\" + 0.031*\"acute\" + 0.029*\"patients\" + 0.025*\"syndrome\" + 0.024*\"severe\" + 0.014*\"clinical\" + 0.013*\"coronavirus\" + 0.012*\"pneumonia\"\n",
            "\n",
            "Score: 0.01389092206954956\t \n",
            "Topic: 0.172*\"covid\" + 0.168*\"19\" + 0.022*\"coronavirus\" + 0.019*\"pandem\" + 0.018*\"disease\" + 0.018*\"pandemic\" + 0.017*\"2019\" + 0.015*\"patients\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGOW6QRUUGft"
      },
      "source": [
        "Performance evaluation of LDA using TF-IDF "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1zpvn2-TwrU",
        "outputId": "f0a5839c-fb66-4bb0-8c66-c0208fb0cf43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "for index, score in sorted(lda_model_tfidf[corpus[13]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 8)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.5284973382949829\t \n",
            "Topic: 0.012*\"virus\" + 0.010*\"sars\" + 0.009*\"cov\" + 0.008*\"2\" + 0.007*\"coronavirus\" + 0.007*\"protein\" + 0.006*\"human\" + 0.005*\"viral\"\n",
            "\n",
            "Score: 0.3881185054779053\t \n",
            "Topic: 0.004*\"laparoscopic\" + 0.004*\"covid\" + 0.004*\"19\" + 0.004*\"plasma\" + 0.004*\"convalescent\" + 0.004*\"surgery\" + 0.003*\"single\" + 0.003*\"intubation\"\n",
            "\n",
            "Score: 0.013904414139688015\t \n",
            "Topic: 0.014*\"covid\" + 0.014*\"19\" + 0.010*\"health\" + 0.009*\"pandemic\" + 0.008*\"pandem\" + 0.007*\"care\" + 0.006*\"outbreak\" + 0.005*\"impact\"\n",
            "\n",
            "Score: 0.013899390585720539\t \n",
            "Topic: 0.009*\"19\" + 0.009*\"covid\" + 0.006*\"angiotensin\" + 0.004*\"patients\" + 0.004*\"disease\" + 0.004*\"wuhan\" + 0.004*\"coronavirus\" + 0.003*\"diabetes\"\n",
            "\n",
            "Score: 0.013899218291044235\t \n",
            "Topic: 0.011*\"respiratory\" + 0.011*\"patients\" + 0.011*\"19\" + 0.011*\"covid\" + 0.010*\"coronavirus\" + 0.009*\"2019\" + 0.009*\"disease\" + 0.008*\"acute\"\n",
            "\n",
            "Score: 0.013897056691348553\t \n",
            "Topic: 0.009*\"covid\" + 0.009*\"19\" + 0.004*\"social\" + 0.004*\"pandem\" + 0.004*\"letter\" + 0.004*\"distancing\" + 0.004*\"pandemic\" + 0.004*\"health\"\n",
            "\n",
            "Score: 0.013892809860408306\t \n",
            "Topic: 0.007*\"covid\" + 0.007*\"19\" + 0.004*\"anxiety\" + 0.003*\"fatality\" + 0.003*\"storm\" + 0.003*\"pandem\" + 0.002*\"pandemic\" + 0.002*\"radiology\"\n",
            "\n",
            "Score: 0.013891260139644146\t \n",
            "Topic: 0.010*\"covid\" + 0.009*\"19\" + 0.005*\"pandem\" + 0.004*\"pandemic\" + 0.003*\"hydroxychloroquine\" + 0.003*\"stroke\" + 0.003*\"chloroquine\" + 0.002*\"during\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrXiCbhwUP6E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}